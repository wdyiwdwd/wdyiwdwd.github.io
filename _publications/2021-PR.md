---
title: "A Two-Level Framework for Place Recognition with 3D Lidar Based on Spatial Relation Graph"
collection: publications
permalink: /publication/SRG
excerpt: 'A Two-Level Framework for Place Recognition with 3D Lidar Based on Spatial Relation Graph'
date: 2021-04-10
venue: 'Pattern Recognition'
paperurl: 'http://wdyiwdwd.github.io/files/SRG.pdf'
citation: 'Y. Gong, F. Sun, J. Yuan, W. Zhu and Q. Sun, "A Two-Level Framework for Place Recognition with 3D Lidar Based on Spatial Relation Graph," in Pattern Recognition, vol. 120, pp. 108171, 2021.'
---

[A Two-Level Framework for Place Recognition with 3D Lidar Based on Spatial Relation Graph](https://www.sciencedirect.com/science/article/abs/pii/S0031320321003587)

## Abstract

In the field of robotics, due to the complexity of real environments, place recognition using the 3D LiDAR is always a challenging problem. The spatial relations of internal structures underlying the LiDAR data from different places are distinguishable, which can be used to describe the environment. In this paper, we utilize the spatial relations of internal structures and propose a two-level framework for 3D LiDAR place recognition based on the spatial relation graph (SRG). At first, the proposed framework segments the point cloud into multiple clusters, then the features of the clusters and the spatial relation descriptors (SRDs) between the clusters are extracted, and the point cloud is represented by the SRG, which uses the clusters as the nodes and their spatial relations as the edges. After that, we propose a two-level matching model in which two different models are fused for accurately and efficiently matching the SRGs, including the upper-level searching model (U-LSM) and lower-level matching model (L-LMM). In the U-LSM, an incremental bag-of-words model is used to search for candidate SRGs through the distribution of the SRDs in the SRG. In the L-LMM, we utilize the improved spectral method to calculate similarities between the current SRG and the candidates. The experimental results demonstrate that our framework achieves good precision, recall and viewpoint robustness on both public benchmarks and self-built campus dataset.

![img](http://wdyiwdwd.github.io/images/SRG.jpg)

<!-- ## Code

- [ASE-Encoder](https://github.com/wdyiwdwd/ASE-Encoder) -->