---
title: "语义特征GICP点云配准方案"
collection: projects
type: "Project"
permalink: /projects/2022-05-26-sgicp
venue: "CICV"
date: 2022-05-26
location: "Beijing, China"
---

语义特征GICP点云配准方案

## GICP算法原理

与传统ICP一样地，最近点的搜索仍旧使用基于欧氏距离的方法，便于使用kd-tree进行搜索过程的加速。假设两个有序点集\\(A=\{a_i\}_{i=1,\dots,N}\\)和\\(B=\{b_i\}_{i=1,\dots,N}\\)，其中\\(a_i\\)和\\(b_i\\)表示具有关联关系的一对点。

假设这两个点集分别采样自高斯概率分布，即\\(a_i\sim\mathcal{N}(\hat{a}_i,C^A_i)\\)和\\(b_i\sim\mathcal{N}(\hat{b}_i,C^B_i)\\)，对于正确的传感器位姿变换\\(T^*\\)，有

$$
\hat{b}_i=T^*\hat{a}_i
$$

对于未经优化的位姿变换\\(T\\)，定义残差\\(d_i(T)=b_i-Ta_i\\)。由于\\(a_i\\)和\\(b_i\\)采样自相互独立的高斯分布，因此有

$$
\begin{aligned}
d_i(T^*)&\sim\mathcal{N}
\left(\hat{b}_i-T^*\hat{a}_i,C_i^B+T^*C_i^AT^{*T}\right)\\
&=\mathcal{N}
\left(0,C_i^B+T^*C_i^AT^{*T}\right)
\end{aligned}
$$

接下来，使用MLE方法对\\(T\\)进行求解。

$$
\begin{aligned}
T=&\arg\max_T\prod_ip(d_i(T))
=\arg\max_T\sum_i\log(p(d_i(T)))\\
&\arg\min_T
\sum_i
d_i(T)^T
(C_i^B+TC_i^BT^T)^{-1}
d_i(T)\\
\end{aligned}
$$

上式给出了GICP算法的优化目标，其中协方差矩阵\\(C_i^B\\)和\\(C_i^A\\)的具体形式不同时，GICP可退化为不同类型的ICP算法变种形式。当满足\\(C_i^B=I,C_i^A=0\\)时，即退化为传统ICP算法。

GICP算法的实现基于一个基本假设，即待匹配点云采样自三维空间中的二维微分流形(2-manifold)，满足局部可微性。对于同一场景的两次数据采集，无法保证每次采样的点都位于同一位置，因此，每个点只在局部表面法向量的方向上提供较强约束。基于此，假设每个点都采样自某个特定的分布，其特点是在表面法向量方向上的协方差非常小，而沿该点所在局部平面分布的协方差很大。例如，对于法向量沿x轴分布的点，其协方差矩阵定义为

$$
C_e=
\begin{bmatrix}
\epsilon & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}
$$

其中\\(\epsilon\\)表示一个非常小的数，代表点的分布在法向量方向上的不确定度很小。令\\(\mu_i\\)和\\(\nu_i\\)分别表示\\(b_i\\)和\\(a_i\\)处的法向量，\\(R_\alpha\\)代表将x轴旋转至向量\\(\alpha\\)的变换，则\\(C_i^B\\)和\\(C_i^A\\)可以计算为

$$
\begin{aligned}
&C_i^B=
R_{\mu_i}C_eR_{\mu_i}^T\\
&C_i^A=
R_{\nu_i}C_eR_{\nu_i}^T
\end{aligned}
$$

<img src="https://sunqinxuan.github.io/images/projects-2022-05-26-img1.png" alt="gicp_illus" style="zoom:80%;" />

图1 plane-to-plane distance

## Semantic-GICP算法设计

对于面向AVP的语义SLAM方案，语义标线在三维空间中多以线条形式存在，因此，以上对于GICP算法的假设便不再适用，待匹配点云应采样自三维空间中的一维微分流形(1-manifold)，也满足局部可微，而采样点的局部结构则应以直线的形式进行拟合。基于以上考虑，设计并提出针对AVP场景的Semantic-GICP (SGICP)算法。

假设每个点都采样自某一个方向上有很大的不确定度，而另外两个方向上有较小不确定度的线状分布，即

$$
C_e=
\begin{bmatrix}
1 & 0 & 0 \\
0 & \epsilon & 0 \\
0 & 0 & \epsilon
\end{bmatrix}
$$

令\\(\mu_i\\)和\\(\nu_i\\)分别表示\\(b_i\\)和\\(a_i\\)处的局部直线方向向量，\\(R_\alpha\\)代表将x轴旋转至向量\\(\alpha\\)的变换，则\\(C_i^B\\)和\\(C_i^A\\)同样可以计算为

$$
\begin{aligned}
&C_i^B=
R_{\mu_i}C_eR_{\mu_i}^T\\
&C_i^A=
R_{\nu_i}C_eR_{\nu_i}^T
\end{aligned}
$$

这样一来，协方差矩阵在垂直于局部直线方向会为误差函数的求解提供一个相对较强的约束，而在沿直线方向上的约束较弱，极大的降低了错误关联以及采样点处不同几何结构对位姿优化结果的影响。

![img](https://sunqinxuan.github.io/images/projects-2022-05-26-img2.png)

![img](https://sunqinxuan.github.io/images/projects-2022-05-26-img3.png)

![img](https://sunqinxuan.github.io/images/projects-2022-05-26-img4.png)

![img](https://sunqinxuan.github.io/images/projects-2022-05-26-img5.png)

![img](https://sunqinxuan.github.io/images/projects-2022-05-26-img6.png)

![img](https://sunqinxuan.github.io/images/projects-2022-05-26-img7.png)


## 实验结果

| registration method | RPE RMSE (VO) [m] | APE RMSE (optimized) [m] |
| ------------------- | ----------------- | ------------------------ |
| SGICP               | **0.003545**      | **0.023295**             |
| SICP                | 0.007652          | 0.040912                 |
| ICP (PCL)           | 0.008463          | 0.034878                 |
| ICP_SVD             | 0.006735          | 0.086893                 |
| ICP_Normal (PCL)    | 0.009387          | 0.043041                 |

表1 多种基于ICP的扫描匹配算法精度对比


![img](https://sunqinxuan.github.io/images/projects-2022-05-26-img8.png)

图2 SGICP的RPE误差曲线


![img](https://sunqinxuan.github.io/images/projects-2022-05-26-img9.png)

图3 SGICP的APE误差轨迹


![img](https://sunqinxuan.github.io/images/projects-2022-05-26-img10.png)

图4 SGICP建图结果


![img](https://sunqinxuan.github.io/images/projects-2022-05-26-img11.png)

图5 多种基于ICP的扫描匹配算法运行时间对比
















## 1.环视图像拼接(AVM)意义及目标

在自动驾驶或者自主泊车系统中，环视全景图像拼接可以消除车辆周围的视觉盲点，帮助驾驶员更加直观地确认周围路况。在本项目中，需要在环视全景图像中完成地面标线的语义分割，用于后续建图和定位。本方案基于车体四周安装的四个180&deg;鱼眼相机，完成环视图像拼接。

## 2.AVM算法原理

### 2.0 鱼眼图像校正

根据鱼眼相机内参标定结果，对鱼眼相机图像进行校正，如图2.1.1所示。

![result_screenshot_18.09.2021](https://sunqinxuan.github.io/images/projects-2021-10-13-img1.png)

图2.1.1 鱼眼图像校正: (左)校正前 (右)校正后

### 2.1 俯视变换

经过相机-车体外参标定，可以得到右、前、左、后四个环视相机的相对于车体后轮中心的位姿分别为\\(T_{wc_1}\\)、\\(T_{wc_2}\\)、\\(T_{wc_3}\\)和\\(T_{wc_4}\\)。已知IMU安装在车体后轴中心，假设车体后轮间距为$d$，后轴高度为$h$，则可知车体左后轮坐标系到IMU坐标系(即为车体坐标系)的变换为

$$
T_{vw}=
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & d/2 \\
0 & 0 & 1 & -h \\
0 & 0 & 0 & 1
\end{bmatrix}
$$

假设地面上一点\\(p\\)在车体坐标系下的坐标为\\(p_{v}\\)，对应齐次坐标为\\(\tilde{p}_v\\)，以右视相机为例，该点在相机坐标系下的齐次坐标可以计算为

$$
\tilde{p}_{c1}=T_{wc_1}^{-1}T_{vw}^{-1}\tilde{p}_v
$$

通过相机内参标定获得的相机内参矩阵\\(K\\)和畸变模型参数\\(D\\)，根据鱼眼相机模型，可以得到\\(p_{c1}\\)对应鱼眼图像的像素坐标\\((u_{c1},v_{c1})^T\\)。


### 2.2 环视图像生成

车体周围生成环视图像的区域大小为\\(L\times L\\)，将此区域栅格化成为\\(N\times N\\)的单元格，每一个单元格对应环视图像的一个像素，则每个像素的物理尺寸为\\({L}/{N}\\)。假设车体坐标系原点在地面上的垂直投影点对应的环视图像像素坐标为\\((c_x,c_y)^T\\)，则对于任一像素点\\((u,v)^T\\)，其对应地面点在车体坐标系下的3D坐标\\(p_v\\)为

$$
p_v=
\begin{bmatrix}
(c_x-u)\frac{L}{N} \\
(c_y-v)\frac{L}{N} \\
-h
\end{bmatrix}
$$

根据2.2节内容，可以直接得到$p_v$对应的图像平面像素坐标\\((u_{c},v_{c})^T\\)，对该像素坐标分别进行上下取整，可以得到四个离散坐标值，分别记为\\((u_{c\_floor},v_{c\_floor})^T\\)、\\((u_{c\_floor},v_{c\_ceil})^T\\)、\\((u_{c\_ceil},v_{c\_floor})^T\\)和\\((u_{c\_ceil},v_{c\_ceil})^T\\)，进行双线性插值可得

$$
f(u_c,v_{c\_floor})=
\frac{u_{c\_ceil}-u_c}{u_{c\_ceil}-u_{c\_floor}}
f(u_{c\_floor},v_{c\_floor})
+\frac{u_c-u_{c\_floor}}{u_{c\_ceil}-u_{c\_floor}}
f(u_{c\_ceil},v_{c\_floor}) 
$$

$$
f(u_c,v_{c\_ceil})=
\frac{u_{c\_ceil}-u_c}{u_{c\_ceil}-u_{c\_floor}}
f(u_{c\_floor},v_{c\_ceil})
+\frac{u_c-u_{c\_floor}}{u_{c\_ceil}-u_{c\_floor}}
f(u_{c\_ceil},v_{c\_ceil}) 
$$

$$
f(u_c,v_c)=
\frac{v_{c\_ceil}-v_c}{v_{c\_ceil}-v_{c\_floor}}
f(u_{c},v_{c\_floor})
+\frac{v_c-v_{c\_floor}}{v_{c\_ceil}-v_{c\_floor}}
f(u_{c},v_{c\_ceil}) 
$$

其中，\\(f(u_c,v_c)\\)表示像素坐标\\((u_{c},v_{c})^T\\)处的图像颜色值。至此得到环视图像\\((u,v)^T\\)坐标处的颜色值，即完成环视图像的生成。

$$
f_{AVM}(u,v)=f(u_c,v_c)
$$


### 2.3 视野重叠区域处理

对于安装在车体四周的180&deg;鱼眼相机，两两之间存在视野重叠区域，如图2.3.1所示，I、III、VI和VIII四个区域内的点，可能同时被相邻的两个相机观测到，对于这些点，需要进行额外的融合处理。

<img src="https://sunqinxuan.github.io/images/projects-2021-10-13-img2.png" alt="Screenshot from 2021-09-22 09-30-14" style="zoom:50%;" />

图2.3.1 车体四周区域划分

不失一般性，以区域III为例，假设其中一点\\((u,v)^T\\)可以被右视相机和前视相机同时观测到，其对应右视相机和前视相机图像上的像素坐标分别为\\((u_{c1},v_{c1})^T\\)和\\((u_{c2},v_{c2})^T\\)。另外，假设右视和前视相机图像平面中心点分别为\\((c_{x1},c_{y1})^T\\)和\\((c_{x2},c_{y2})^T\\)，令

$$
\rho_1=\sqrt{(u_{c1}-c_{x1})^2+(v_{c1}-c_{y1})^2} 
$$

$$
\rho_2=\sqrt{(u_{c2}-c_{x2})^2+(v_{c2}-c_{y2})^2}
$$

基于越靠近图像边缘的点，畸变越大的原则，设计视野重叠区域融合方案为

$$
f_{AVM}(u,v)=
\frac{1}{\rho_1}f_{c1}(u_{c1},v_{c1})
+\frac{1}{\rho_2}f_{c2}(u_{c2},v_{c2})
$$

## 3.AVM系统实现方案

### 3.1 AVM算法流程

图3.1.1为AVM算法总体流程，其输入为鱼眼相机图像、相机内外参以及给定AVM生成范围，输出为AVM环视图像，处理过程主要包含逆向投影变换、双线性插值和视野重合区域融合。

```mermaid
graph LR
input_img(鱼眼相机图像)
input_cam(相机内外参)
output(AVM图像)
AVMcoords(AVM生成范围)
AVM2vehicle[逆向投影变换]
bilinear_interp[双线性插值]
overlap[视野重合区域融合]

AVMcoords --> AVM2vehicle 
input_cam --> AVM2vehicle 
AVM2vehicle --> bilinear_interp
input_img --> bilinear_interp
bilinear_interp --> overlap
overlap --> output
```

图3.1.1 AVM算法流程

逆向投影变换主要将AVM环视图像中的各个像素点对应的地面点3D坐标变换到环视相机图像平面坐标系，将得到的像素坐标离散化后可以获取对应的图像颜色值。接着，通过双线性插值算法，计算得到对应AVM图像坐标处的颜色值。最后，对相邻相机的视野重合区域的像素点进行融合，得到AVM图像结果。

### 3.2 AVM类结构设计

```mermaid
classDiagram
	AVM <-- AVMFlow
	class AVMFlow {
	-avm_ptr_;
	-camera_info_sub_ptr;
	-image_sub_ptr;
	-avm_image_pub_ptr_;
	+ReadData();
	+HasData();
	+ValidData();
	+RunData();
	+PublishData();
	}
	class AVM {
	-trans_vehicle_wheel_;
	+Run();
	-InverseProjection();
	-BilinearInterp();
	-OverlapFusion();
	}
```

#### 3.2.1 AVMFlow类

AVMFlow类是适配ROS接口的AVM拼接数据流类，包含对环视相机图像数据以及相机内外参数据的读取、存在状态判断、有效状态判断、数据处理以及AVM拼接图像数据的发布。该类的主要方法有：

```c++
bool ReadData(); // 从ROS的消息队列中读取数据，成功返回true;
bool HasData(); // 判断当前时刻所需数据队列是否非空，非空返回true;
bool ValidData(); // 判断最新数据是否有效，有效返回true;
bool RunData(); // 执行AVM图像拼接，成功返回true;
bool PublishData(); // 发布AVM图像数据，成功返回true;
```

该类的主要成员变量有：

```c++
avm_ptr_; // AVM图像拼接核心处理类对象指针;
camera_info_sub_ptr_; // 相机内外参数据接收指针;
image_sub_ptr_; // 环视相机图像数据接收指针;
avm_image_pub_ptr_; // AVM图像数据发布指针;
```

#### 3.2.2 AVM类

AVM类是AVM图像拼接核心处理类，包含对给定AVM图像观测地面范围进行逆向投影、环视图像颜色值的双线性插值以及对相邻相机视野重合区域的融合处理。该类的主要方法有：

```c++
bool Run(); // 核心函数对外接口;
bool InverseProjection(); // 逆向投影功能函数;
bool BilinearInterp(); // 双线性插值函数;
bool OverlapFusion(); // 视野重合区域融合函数;
```

该类的主要成员变量有：

```c++
trans_vehicle_wheel_; // 标定布十字交叉处坐标系到车体坐标系的变换;
```

## 4.自适应IPM算法

### 4.1 算法原理

使用标定好的相机-车体外参生成AVM图像时，需要满足车体坐标系OXY平面与地面保持平行，但是在车辆加减速以及经过减速带时，无法保持车体与地面的平行。因此，使用组合导航给出的车体俯仰角以及横滚角的观测值，在自适应IPM算法过程中对车体的姿态进行补偿。

在自适应IPM算法中，假设组合导航系统提供的车体俯仰角和横滚角分别为\\(\theta\\)和\\(\varphi\\)，根据车体坐标系的设置，可知须补偿的车体旋转变换为

$$
R_{adapt}=
R_{x,-\varphi}R_{y,-\theta}=
\begin{bmatrix}
1 & 0 & 0 \\
0 & \cos(-\varphi) & \sin(-\varphi) \\
0 & -\sin(-\varphi) & \cos(-\varphi) \\
\end{bmatrix}
\begin{bmatrix}
\cos(-\varphi) & 0 & -\sin(-\varphi) \\
0 & 1 & 0 \\
\sin(-\varphi) & 0 & \cos(-\varphi) \\
\end{bmatrix}
$$

补偿后，车体坐标系到车体后轮（即标定布）坐标系变换为

$$
T_{wv}'=T_{wv}\cdot
\begin{bmatrix}
R_{adapt} & \boldsymbol 0 \\
\boldsymbol 0^T & 1 
\end{bmatrix}
$$

### 4.2 调试记录

在通过停车场不同区域之间的连接处时，由于坡度较大，可以直观看出补偿效果，如图4.2.1所示。

<img src="https://sunqinxuan.github.io/images/projects-2021-10-13-img3.png" style="zoom:70%;" />

<img src="https://sunqinxuan.github.io/images/projects-2021-10-13-img4.png" alt="Screenshot from 2021-10-08 15-26-55" style="zoom:70%;" />

图4.2.1 地下停车场自适应IPM算法补偿效果：(左)补偿前，(右)补偿后

在车辆通过减速带时，难以直观看出补偿效果。输出俯仰角变化曲线如图4.2.2所示，前后三个较大的尖峰对应出入停车场的上下坡过程，而中间四个脉冲对应停车场区域之间连接处，除此外，不存在特定波型与减速带产生明确的对应关系。

![image-2](https://sunqinxuan.github.io/images/projects-2021-10-13-img5.png)

图4.2.2 地下停车场俯仰角变化曲线

同时输出俯仰角以及其对应观测方差的曲线如图4.2.3所示，可以看出除了上述特定波型外，曲线其他地方的波动基本都在方差范围以内，换言之，有很大可能性是由噪声引起的，因此，将其用于车体姿态的补偿可以没有太大意义。

![image-3](https://sunqinxuan.github.io/images/projects-2021-10-13-img6.png)

图4.2.3 地下停车场俯仰角及其方差变化曲线

综上，组合导航系统给出的姿态估计结果，只能用于补偿能带来明显倾斜感的车体姿态变化，而对于平常路面颠簸、经过减速带以及车辆加减速所带来的车体姿态变化，则无法通过组合导航系统给出足够准确的估计。

## 5.运行结果

### 5.1 场景一：地下停车场

<iframe width="1077" height="1076" src="https://www.youtube.com/embed/XHa4P9Y-m7I" title="vokoscreenNG 2024 02 06 17 09 04" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### 5.2 场景二：开放道路

<iframe width="1077" height="1076" src="https://www.youtube.com/embed/6cUQkdM8izw" title="vokoscreenNG 2024 02 06 17 23 13" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## 6.相关链接

代码：
- [avm](https://github.com/sunqinxuan/avm)